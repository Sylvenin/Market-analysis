{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca396013",
   "metadata": {},
   "source": [
    "# Projet 9 : Entreprise \"La poule qui chante\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640733f7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sommaire\n",
    "* [Gestion des données](#chapter1)\n",
    "\n",
    "    * [Import des données](#section_1_1)\n",
    "    \n",
    "    * [Vérification des données](#section_1_2)\n",
    "        * [Description des données](#section_1_2_1)\n",
    "        * [Organisation des données](#section_1_2_2)\n",
    "        * [Vérification des doublons](#section_1_2_3)\n",
    "        * [Vérification des Nan](#section_1_2_4)\n",
    "        \n",
    "    * [Organisation des données](#section_1_3)\n",
    "        * [Pivot](#section_1_3_1)\n",
    "        * [Fusion des données](#section_1_3_2)\n",
    "        * [Gestion des outliers](#section_1_3_3)\n",
    "        \n",
    "* [Analyse composantes - clusters](#chapter2)\n",
    "\n",
    "    * [Analyse des composantes](#section_2_1)\n",
    "        * [Analyse des Composantes Principales (ACP)](#section_2_1_1)\n",
    "        * [Biplot et charges factorielles](#section_2_1_2)\n",
    "        * [Éboulis des valeurs propres et coude](#section_2_1_3)\n",
    "        \n",
    "    * [Analyse des clusters](#section_2_2)\n",
    "        * [Analyse via des modèles arbitraires](#section_2_2_1)\n",
    "        * [Dendrogramme, ou Classification Ascendante Hiérarchique](#section_2_2_2)\n",
    "        * [Algorithme Kmeans](#section_2_2_3)\n",
    "        * [Analyse des résultats](#section_2_2_4)\n",
    "        * [Évaluation du cluster conservé](#section_2_2_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f11a6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gestion des données <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29684c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Import des données <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167fefb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import des modules\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44c5e41",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Avenmythril\\\\Desktop\\\\Formations\\\\DAn\\\\Projet 9\\\\DAN-P9-data\\\\DisponibiliteAlimentaire_2017.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18636\\4146568454.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import des données\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdispo_alim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Avenmythril\\Desktop\\Formations\\DAn\\Projet 9\\DAN-P9-data\\DisponibiliteAlimentaire_2017.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Avenmythril\\Desktop\\Formations\\DAn\\Projet 9\\DAN-P9-data\\Population_2000_2018.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Avenmythril\\\\Desktop\\\\Formations\\\\DAn\\\\Projet 9\\\\DAN-P9-data\\\\DisponibiliteAlimentaire_2017.csv'"
     ]
    }
   ],
   "source": [
    "# import des données\n",
    "dispo_alim = pd.read_csv (r'C:\\Users\\Avenmythril\\Desktop\\Formations\\DAn\\Projet 9\\DAN-P9-data\\DisponibiliteAlimentaire_2017.csv')\n",
    "population = pd.read_csv (r'C:\\Users\\Avenmythril\\Desktop\\Formations\\DAn\\Projet 9\\DAN-P9-data\\Population_2000_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97630699",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Vérification des données <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc80336",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Description des données <a class=\"anchor\" id=\"section_1_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602ceed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on effectue un describe sur chaque fichier\n",
    "dispo_alim.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2e379",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cette étape nous permet de repérer différenes colonnes ayant des outliers, qu'il faudra donc gérer plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a2f5b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on effectue aussi un head sur chaque fichier avant de trier\n",
    "dispo_alim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dba0bb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Organisation des données <a class=\"anchor\" id=\"section_1_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c5fa92",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ici, nous allons préparer les données pertinentes avant la fusion, et notamment supprimer les années autres que 2017 car c'est la seule année présente dans le df dispo_alim. Nous allons aussi éliminer les colonnes inutiles dans notre recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b860993",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on supprime les colonnes inutiles\n",
    "columns_to_drop = ['Code zone', 'Code Élément', 'Élément', 'Unité', 'Code année', 'Code Domaine', 'Domaine', 'Symbole', 'Description du Symbole', 'Note', 'Code Produit', 'Produit']\n",
    "population = population.drop(columns=columns_to_drop)\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78642afe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on filtre les lignes où l'année est égale à 2017, car c'est la seule année présente dans l'autre df\n",
    "population = population[population['Année'] == 2017]\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d157e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# suppression des colonnes inutiles avant fusion\n",
    "columns_to_drop = ['Code Domaine', 'Domaine', 'Code zone', 'Unité', 'Code Élément', 'Code Produit', 'Code année', 'Symbole', 'Description du Symbole']\n",
    "dispo_alim = dispo_alim.drop(columns=columns_to_drop)\n",
    "dispo_alim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02ee36",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dernier point : nous allons supprimer les \"Produit\" autres que la viande de volaille et les oeufs, qui sont les seuls produits concernant notre entreprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c72b6d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# création du df contenant uniquement les produits qui nous intéressent\n",
    "produits_volaille = dispo_alim[dispo_alim['Produit'].isin(['Viande de Volailles', 'Oeufs'])]\n",
    "\n",
    "# tri du df pour un tri décroissant\n",
    "produits_volaille = produits_volaille.sort_values(by='Valeur', ascending=False)\n",
    "\n",
    "produits_volaille.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1891032",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Vérification des doublons <a class=\"anchor\" id=\"section_1_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505400a9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on recherche les doublons dans dispo_alim\n",
    "duplicates = dispo_alim[dispo_alim.duplicated()]\n",
    "print(duplicates)\n",
    "\n",
    "# on filtre produits_volaille en fonction des indices des doublons dans dispo_alim\n",
    "produits_volaille_filtered = produits_volaille[produits_volaille.index.isin(duplicates.index)]\n",
    "print(produits_volaille_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59ab7f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Aucun doublon n'est à déclarer dans les deux tableaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40039474",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Vérification des données NaN <a class=\"anchor\" id=\"section_1_2_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3452cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# vérification de la quantité de données NaN\n",
    "print(produits_volaille.isnull().sum())\n",
    "print ('')\n",
    "print(population.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ac44a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On ne remarque aucune donnée manquante, ce qui est un bon signe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa8f54",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Organisation des données <a class=\"anchor\" id=\"section_1_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06672d7b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pivot <a class=\"anchor\" id=\"section_1_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c795b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Afin de rechercher de manière efficace dans les données, nous allons effectuer un pivot sur le dataframe dispo_alim, en ciblant la colonne \"Produit\". Cela nous permettra de définir les colonnes selon l'utilisation des produits alimentaires (import, export, disponibilité...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d69006",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "produits_volaille.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d345b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on pivote le df pour obtenir une seule ligne par pays et produit\n",
    "produits_volaille_pivot = produits_volaille.pivot_table(index=['Zone', 'Année'],\n",
    "                                                      columns='Élément',\n",
    "                                                      values='Valeur',\n",
    "                                                      aggfunc='sum')\n",
    "\n",
    "# on réinitialise l'index\n",
    "produits_volaille_pivot = produits_volaille_pivot.reset_index()\n",
    "\n",
    "# on remplacer les valeurs NaN par des zéros si nécessaire\n",
    "produits_volaille_pivot = produits_volaille_pivot.fillna(0)\n",
    "\n",
    "# affichage des données\n",
    "produits_volaille_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb896243",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En utilisant l'équation suivante, on peut ajuster l'exportation, où beaucoup de données sont manquantes :\n",
    "\n",
    "Calcul de l'exportation: Production - Disponibilité intérieure  + Importations + Variation de stock + Autres utilisations - Nourriture animale - Pertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d58fd8",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calcul de la colonne Exportations\n",
    "produits_volaille_pivot['Exportations - Quantité'] = produits_volaille_pivot['Production'] + produits_volaille_pivot['Importations - Quantité'] - produits_volaille_pivot['Disponibilité intérieure'] + produits_volaille_pivot['Variation de stock'] + produits_volaille_pivot['Autres utilisations (non alimentaire)'] - produits_volaille_pivot['Aliments pour animaux'] - produits_volaille_pivot['Pertes']\n",
    "\n",
    "# affichage\n",
    "produits_volaille_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c797627",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fusion des tableaux <a class=\"anchor\" id=\"section_1_3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a2f0e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rattachement de la table population à la table produits_volaille\n",
    "pop_et_dispo = pd.merge(population, produits_volaille_pivot, on=['Zone', 'Année'], how='inner')\n",
    "pop_et_dispo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34269f1e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pour mieux comprendre et utiliser les données par la suite, nous allons renommer la colonne \"Valeur\" en \"Population\", et diviser chaque autre colonne par le nombre d'habitants. Cela nous permettra de nous passer de la population dans le prochain calcul d'outliers. Nous conservons tout de même cette dernière pour s'assurer de certaines corrélations plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cae52b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# la colonne 'Valeur' devient 'Population'\n",
    "pop_et_dispo = pop_et_dispo.rename(columns={'Valeur': 'Population'})\n",
    "\n",
    "# on multiplie la populaion par 1000, car la meusre était en millier d'habitants\n",
    "pop_et_dispo['Population'] = pop_et_dispo['Population'] * 1000\n",
    "\n",
    "# on liste les colonnes quantitatives (sauf 'Population')\n",
    "colonnes_quantitatives = pop_et_dispo.columns[(pop_et_dispo.dtypes != 'object') & (pop_et_dispo.columns != 'Population')]\n",
    "\n",
    "# on divise chaque colonne quantitative par la colonne 'Population'\n",
    "pop_et_dispo[colonnes_quantitatives] = pop_et_dispo[colonnes_quantitatives].div(pop_et_dispo['Population'], axis=0)\n",
    "\n",
    "# et on affiche le résultat\n",
    "pop_et_dispo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91c86b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La modification du tableau suite au pivot fait ressortir de nouvelles colonnes inutiles dans notre analyse. En effet, certaines utilisation des produits n'auront aucun impact dans les futurs résultats, et limiter le nombre de variables permet de réduire en conséquence la perte des données après l'ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158b18b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on supprime les nouvelles colonnes inutiles\n",
    "columns_to_drop = ['Année', 'Alimentation pour touristes', 'Aliments pour animaux', 'Disponibilité alimentaire (Kcal/personne/jour)', 'Autres utilisations (non alimentaire)', 'Disponibilité de matière grasse en quantité (g/personne/jour)', 'Disponibilité de protéines en quantité (g/personne/jour)', 'Pertes', 'Résidus', 'Semences', 'Nourriture', 'Traitement', 'Variation de stock']\n",
    "pop_et_dispo = pop_et_dispo.drop(columns=columns_to_drop)\n",
    "pop_et_dispo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959837e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on conserve les données qui nous semblent le plus intéressantes\n",
    "colonnes_interessantes = ['Disponibilité intérieure', 'Importations - Quantité', 'Production', 'Exportations - Quantité', 'Disponibilité alimentaire en quantité (kg/personne/an)']\n",
    "\n",
    "# création du sous-df\n",
    "fusion_simplifiée = pop_et_dispo[colonnes_interessantes]\n",
    "\n",
    "# affichage d'un boxplot par colonnes\n",
    "plt.figure(figsize=(10, 6))\n",
    "fusion_simplifiée.boxplot()\n",
    "plt.title(\"Boxplot pour les colonnes sélectionnées\")\n",
    "plt.xlabel(\"Colonnes\")\n",
    "plt.ylabel(\"Valeurs\")\n",
    "plt.xticks(rotation=45)  # pour faire pivoter les noms de colonnes si nécessaire\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf50c7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On distingue des outliers dans les colonnes \"Importations\", \"Exportations\" et \"Disponibilité alimentaire\". Nous devons donc effectuer une gestion sur ces trois colonnes principalement.\n",
    "\n",
    "Pour rappel, la colonne \"Population\" n'as pas besoin d'être traitée, car nous avons uniformisé les données selon le nombre d'habitants précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0457c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Gestion des outliers <a class=\"anchor\" id=\"section_1_3_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd09768",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# méthode des écarts interquartiles pour analyser les outliers des valeurs d'importation\n",
    "Q1_import = pop_et_dispo['Importations - Quantité'].quantile(0.25)\n",
    "Q3_import = pop_et_dispo['Importations - Quantité'].quantile(0.75)\n",
    "IQR_import = Q3_import - Q1_import\n",
    "\n",
    "lower_bound_import = Q1_import - 1.5 * IQR_import\n",
    "upper_bound_import = Q3_import + 1.5 * IQR_import\n",
    "\n",
    "outliers_import = pop_et_dispo[(pop_et_dispo['Importations - Quantité'] < lower_bound_import) | (pop_et_dispo['Importations - Quantité'] > upper_bound_import)]\n",
    "\n",
    "# méthode des écarts interquartiles pour analyser les outliers des valeurs d'exportation\n",
    "Q1_export = pop_et_dispo['Exportations - Quantité'].quantile(0.25)\n",
    "Q3_export = pop_et_dispo['Exportations - Quantité'].quantile(0.75)\n",
    "IQR_export = Q3_export - Q1_export\n",
    "\n",
    "lower_bound_export = Q1_export - 1.5 * IQR_export\n",
    "upper_bound_export = Q3_export + 1.5 * IQR_export\n",
    "\n",
    "outliers_export = pop_et_dispo[(pop_et_dispo['Exportations - Quantité'] < lower_bound_export) | (pop_et_dispo['Exportations - Quantité'] > upper_bound_export)]\n",
    "\n",
    "# méthode des écarts interquartiles pour analyser les outliers des valeurs de disponibilité alimentaire\n",
    "Q1_alim = pop_et_dispo['Disponibilité alimentaire en quantité (kg/personne/an)'].quantile(0.25)\n",
    "Q3_alim = pop_et_dispo['Disponibilité alimentaire en quantité (kg/personne/an)'].quantile(0.75)\n",
    "IQR_alim = Q3_alim - Q1_alim\n",
    "\n",
    "lower_bound_alim = Q1_alim - 1.5 * IQR_alim\n",
    "upper_bound_alim = Q3_alim + 1.5 * IQR_alim\n",
    "\n",
    "outliers_alim = pop_et_dispo[(pop_et_dispo['Disponibilité alimentaire en quantité (kg/personne/an)'] < lower_bound_alim) | (pop_et_dispo['Disponibilité alimentaire en quantité (kg/personne/an)'] > upper_bound_alim)]\n",
    "\n",
    "# on concat les 3 df en un seul\n",
    "outliers = pd.concat([outliers_import, outliers_export, outliers_alim])\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884fd66",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on souhaite savoir combien de pays ont été considérés comme outliers\n",
    "nombre_total_outliers = len(outliers)\n",
    "print(f\"Le nombre total d'outliers gérés est : {nombre_total_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86582d54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# suppression des outliers\n",
    "data_sans_outliers = pop_et_dispo.drop(outliers.index)\n",
    "data_sans_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317227fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# création des boxplots pour vérification de l'importation\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(data_sans_outliers['Importations - Quantité'], vert=False)\n",
    "plt.xlabel('Importations - Quantité')\n",
    "plt.title('Évaluation de l\\'importation par pays')\n",
    "plt.show()\n",
    "\n",
    "# création des boxplots pour vérification de l'exportation\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(data_sans_outliers['Exportations - Quantité'], vert=False)\n",
    "plt.xlabel('Exportations - Quantité')\n",
    "plt.title('Évaluation de l\\'exportation par pays')\n",
    "plt.show()\n",
    "\n",
    "# création des boxplots pour vérification de la disponibilité alimentaire\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(data_sans_outliers['Disponibilité alimentaire en quantité (kg/personne/an)'], vert=False)\n",
    "plt.xlabel('Disponibilité alimentaire en quantité (kg/personne/an)')\n",
    "plt.title('Évaluation de la disponibilité alimentaire par pays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed803f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le boxplot permet de confirmer que les outliers ont bien été gérés. Cela nous permettra d'utiliser plus bas un algorithme d'analyse plus performant que robuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce138c9",
   "metadata": {},
   "source": [
    "# Analyse composantes - clusters <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48d4e93",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analyse des composantes <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b7892",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Analyse des Composantes Principales <a class=\"anchor\" id=\"section_2_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd22f96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# création d'un df copie, qui nous sera utile pour la fin\n",
    "data_fin = data_sans_outliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a9287",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sélection des colonnes à standardiser\n",
    "cols_to_scale = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# création d'un sous-df avec les colonnes sélectionnées\n",
    "data_to_scale = data_sans_outliers[cols_to_scale]\n",
    "\n",
    "# standardisation avec StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_standard = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "# création d'un df avec les données standardisées\n",
    "data_standard = pd.DataFrame(data_standard, columns=cols_to_scale)\n",
    "\n",
    "# mise à l'échelle avec MinMaxScaler pour mettre les valeurs standardisées dans la plage [-1, 1]\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data_scaled = min_max_scaler.fit_transform(data_standard)\n",
    "\n",
    "# création d'un df avec les données mises à l'échelle\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=cols_to_scale)\n",
    "\n",
    "# on affiche les boxplots avant et après standardisation\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(data_to_scale, vert=False)\n",
    "plt.title('Avant Standardisation')\n",
    "plt.xlabel('Colonnes')\n",
    "plt.ylabel('Valeurs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(data_scaled_df, vert=False)\n",
    "plt.title('Après Standardisation et Mise à l\\'échelle')\n",
    "plt.xlabel('Colonnes')\n",
    "plt.ylabel('Valeurs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8c10e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Les données sont bien normalisées, on peut donc partir sur une ACP sans souci d'échelle.\n",
    "\n",
    "La valeur 1 en ordonnée représente le nombre d'habitants, d'où la conservation des deux données aberrantes. Pour rappel, la population outlier n'a pas été gérée car ce n'est pas un critère d'élimination. On veut éliminer les pays où la demande sera faible, quel que soit leur nombre d'habitants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0358a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on sélectionne les colonnes à inclure dans l'ACP\n",
    "data_to_plot = data_scaled_df[['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']]\n",
    "\n",
    "# on effectue l'ACP pour réduire la dimension à 2 composantes principales\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(data_to_plot)\n",
    "\n",
    "# on crée un nuage de points 2D\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1])\n",
    "plt.title('Nuage de points après ACP (2D)')\n",
    "plt.xlabel('Composante Principale 1')\n",
    "plt.ylabel('Composante Principale 2')\n",
    "\n",
    "# on affiche les noms de pays ou d'observations\n",
    "for i, txt in enumerate(data_sans_outliers['Zone']):\n",
    "    plt.annotate(txt, (data_2d[i, 0], data_2d[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d5084",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sélection des colonnes à inclure dans l'ACP (sans la population)\n",
    "data_to_plot = data_scaled_df[['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']]\n",
    "\n",
    "# analyse de l'ACP réduite à 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "data_3d = pca.fit_transform(data_to_plot)\n",
    "\n",
    "# création du graph 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = data_3d[:, 0]\n",
    "y = data_3d[:, 1]\n",
    "z = data_3d[:, 2]\n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "ax.set_xlabel('Composante Principale 1')\n",
    "ax.set_ylabel('Composante Principale 2')\n",
    "ax.set_zlabel('Composante Principale 3')\n",
    "ax.set_title('Nuage de points après ACP (3D)')\n",
    "\n",
    "# on affiche les noms des pays\n",
    "for i, txt in enumerate(data_sans_outliers['Zone']):\n",
    "    ax.text(x[i], y[i], z[i], txt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663ecdc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cette analyse n'apporte rien en terme de chiffres, mais une visualisation en 3 dimensions permet de distinguer des écarts entre pays que l'absence de profondeur ne permet pas de repérer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090cd886",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on crée la matrice de corrélation\n",
    "matrice_cor = data_scaled_df[cols_to_scale].corr()\n",
    "\n",
    "# création de la heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matrice_cor, annot=True, cmap=\"coolwarm\", square=True, fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Matrice de Corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841e7bb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cette méthode permet de repérer les corrélations entre les différentes dimensions. Cependant, elle n'est pas la plus lisible pour comparer toutes les dimensions en même temps. Essayons une autre méthode, mais gardons en tête certains liens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89827c34",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Biplot et charges factorielles <a class=\"anchor\" id=\"section_2_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ddd00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on sélectionne les colonnes à inclure dans l'ACP\n",
    "cols_to_scale = ['Population', 'Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# standardisation des colonnes sélectionnées\n",
    "scaler = StandardScaler()\n",
    "data_sans_outliers[cols_to_scale] = scaler.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# réalisation de l'ACP\n",
    "pca = PCA()\n",
    "data_pca = pca.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# on cherche les valeurs de variance_ratio\n",
    "variance_ratios = pca.explained_variance_ratio_\n",
    "\n",
    "# calcul du nombre de composantes nécessaires pour atteindre 90% de variance\n",
    "cumulative_variance = np.cumsum(variance_ratios)\n",
    "n_components_for_90_percent_variance = np.argmax(cumulative_variance >= 0.90) + 1\n",
    "\n",
    "# graphique du cercle des charges factorielles\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axhline(0, color='gray', linewidth=0.5)\n",
    "ax.axvline(0, color='gray', linewidth=0.5)\n",
    "\n",
    "# tracé un cercle\n",
    "circle = plt.Circle((0, 0), 1, fill=False, color='gray')\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# tracé des flèches pour chaque variable\n",
    "for i, col in enumerate(cols_to_scale):\n",
    "    x = pca.components_[0, i]\n",
    "    y = pca.components_[1, i]\n",
    "    ax.arrow(0, 0, x, y, head_width=0.05, head_length=0.05, fc='r', ec='r')\n",
    "    ax.text(x, y, col, fontsize=12, ha='left', va='bottom')\n",
    "\n",
    "# titres et labels\n",
    "ax.set_title('Cercle des Charges Factorielles')\n",
    "ax.set_xlabel('Composante Principale 1')\n",
    "ax.set_ylabel('Composante Principale 2')\n",
    "\n",
    "# Affichage du pourcentage de variance expliquée\n",
    "percentage_variance = np.sum(variance_ratios[:2]) * 100\n",
    "ax.text(1.05, 0, f'Variance expliquée :\\n{percentage_variance:.2f}%', fontsize=12, ha='left', va='center', color='b')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print()\n",
    "print(f\"Pour atteindre 90% de variance expliquée, il faut conserver {n_components_for_90_percent_variance} composantes principales.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243b125",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ce graphique est beaucoup plus parlant et montre plusieurs choses :\n",
    "\n",
    "- La population est inversement proportionnelle à l'importation et la disponibilité alimentaire, mais une corrélation positive légère se fait avec la production et la disponibilité intérieure\n",
    "- L'exportation a une corrélation faible avec les autres composantes\n",
    "- La production et la disponibilité intérieure sont fortement correlées et très bien représentées\n",
    "- L'importation et la dispo par personne sont aussi fortement correlées et très bien représentées\n",
    "- Il ne semble pas y avoir de lien entre l'axe \"production/dispo intérieure\" et l'axe \"importations/dispo par pers.\".\n",
    "\n",
    "Afin d'avoir un point de vue encore meilleur, pourquoi ne pas superposer le graphique des charges factorielles et celui de l'ACP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924f299",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sélection des colonnes à inclure dans l'ACP\n",
    "cols_to_scale = ['Population', 'Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# standardisation des colonnes sélectionnées\n",
    "scaler = StandardScaler()\n",
    "data_sans_outliers[cols_to_scale] = scaler.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# réalisation de l'ACP\n",
    "pca = PCA()\n",
    "pca.fit(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# obtention des charges factorielles\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "# idem pour les coordonnées des pays dans l'espace des composantes principales\n",
    "pcs = pca.transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# on crée un biplot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# on trace les flèches des charges factorielles\n",
    "for i, col in enumerate(cols_to_scale):\n",
    "    x = loadings[i, 0]\n",
    "    y = loadings[i, 1]\n",
    "    ax.arrow(0, 0, x, y, head_width=0.05, head_length=0.05, fc='r', ec='r')\n",
    "    ax.text(x, y, col, fontsize=12, ha='left', va='bottom')\n",
    "\n",
    "# on place les pays dans l'espace ACP\n",
    "ax.scatter(pcs[:, 0], pcs[:, 1], alpha=0.5, label='Observations')\n",
    "\n",
    "# titres et labels\n",
    "ax.set_title('Biplot des Composantes Principales')\n",
    "ax.set_xlabel('Composante Principale 1')\n",
    "ax.set_ylabel('Composante Principale 2')\n",
    "ax.legend()\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da6400",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La direction des flèches indique la direction et la force des variables originales dans l'espace des composantes principales. La répartition des pays dans ce \"biplot\" indique leur positionnement par rapport aux variables.\n",
    "\n",
    "Ainsi :\n",
    "\n",
    "   La flèche de la population pointant vers le haut signifie que les pays avec des valeurs élevées dans cette variable sont situés plus haut sur l'axe des composantes principales 2.\n",
    "    Les flèches d'importation et de disponibilité alimentaire pointant vers le bas à droite signifient que les pays avec des valeurs élevées dans ces variables sont situés dans le coin bas-droite de l'espace des composantes principales.\n",
    "\n",
    "Ces identifications nous permettent de distinguer d'emblée des groupes de pays, mais aussi de \"prévoir\" les pays qui peuvent nous intéresser. Dans notre cas, nous allons nous concentrer notamment sur les pays qui importent beaucoup, où la demande est la plus importante.\n",
    "\n",
    "Cas particulier:\n",
    "Le cluster au centre-gauche, où aucune flèche ne pointe directement, peut indiquer que ces observations partagent des caractéristiques spécifiques qui ne sont pas fortement influencées par les variables incluses dans l'ACP, ou encore que les variables qui les définissent le plus ne sont pas les mieux représentées.\n",
    "\n",
    "Afin de continuer notre analyse, il nous faut définir le nombre de composantes à conserver, le tout sans perdre trop de données. Le cercle des charges factorielles était accompagné d'une analyse de la variance cumulative qui estime que 4 composantes suffisent à conserver 90% de nos informations. Essayons une autre méthode pour voir si le résultat diffère."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2fed92",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Éboulis des valeurs propres et coude  <a class=\"anchor\" id=\"section_2_1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e459b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# récupération des valeurs propres à partir de l'ACP\n",
    "eigenvalues = pca.explained_variance_\n",
    "\n",
    "# calcul de la variance cumulée normalisée\n",
    "cumulative_variance = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "# on cherche le coude\n",
    "elbow_index = np.argmax(np.diff(cumulative_variance) < 0.01) + 1\n",
    "\n",
    "# création du graph d'éboulis des valeurs propres avec variance cumulée et coude\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# barres pour les valeurs propres\n",
    "ax1.bar(range(1, len(eigenvalues) + 1), eigenvalues, align='center', label='Valeur Propre', alpha=0.7)\n",
    "ax1.set_xlabel('Composante Principale')\n",
    "ax1.set_ylabel('Valeur Propre', color='tab:blue')\n",
    "ax1.tick_params('y', colors='tab:blue')\n",
    "\n",
    "# ligne pour la variance cumulée\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(1, len(eigenvalues) + 1), cumulative_variance, label='Variance Cumulée', marker='o', color='r')\n",
    "ax2.set_ylabel('Variance Cumulée', color='tab:red')\n",
    "ax2.tick_params('y', colors='tab:red')\n",
    "\n",
    "# point pour le coude\n",
    "ax2.scatter(elbow_index, cumulative_variance[elbow_index - 1], c='green', marker='o', s=100, label='Coude')\n",
    "\n",
    "plt.title('Graphique d\\'Éboulis des Valeurs Propres avec Variance Cumulée et Coude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19705bd1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "D'emblée, deux informations ressortent :\n",
    "- Le coude est à la 5eme composante\n",
    "- la première composante est largement plus impactante que les autres\n",
    "\n",
    "Les deux analyses précédentes ont révélé toutefois un résultat différent :\n",
    "- La méthode du coude indique que 5 composantes seraient nécessaires à l'ACP\n",
    "- La méthode des variances cumulatives estime que 4 composantes sont suffisantes pour conserver plus de 90% de nos données.\n",
    "\n",
    "Afin de limiter au maximum la perte des données, nous allons conserver 5 composantes. Par ailleurs, en rapport avec ce qui a été dit plus tôt, nous ne prendrons pas en compte la poulation dans la gestion des clusters. Il nous reste alors 5 composantes :\n",
    "- La production\n",
    "- L'importation\n",
    "- L'exportation\n",
    "- La disponibilité intérieure\n",
    "- La disponibilité par personne\n",
    "\n",
    "Étape suivante : la définition du nombre de clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ba7ff",
   "metadata": {},
   "source": [
    "## Analyse des clusters <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704412cf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analyse via des modèles arbitraires <a class=\"anchor\" id=\"section_2_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10315fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on sélectionne les colonnes à inclure dans l'analyse K-Means\n",
    "X = data_sans_outliers[cols_to_scale]\n",
    "\n",
    "# test de différentes valeurs de k et enregistrement du résultat\n",
    "k_values = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
    "\n",
    "# on trace les graphique du coude et de la silhouette\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_values, inertias, 'o-')\n",
    "plt.title('Méthode du Coude')\n",
    "plt.xlabel('Nombre de Clusters (k)')\n",
    "plt.ylabel('Inertie')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_values, silhouette_scores, 'o-')\n",
    "plt.title('Score de Silhouette')\n",
    "plt.xlabel('Nombre de Clusters (k)')\n",
    "plt.ylabel('Score de Silhouette')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f93137",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La méthode du coude ne montre pas de cassure nette, ce qui rend le choix du nombre optimal de clusters difficile.\n",
    "\n",
    "Le score de Silhouette quant à lui est censé indiquer l'organisation des clusters, car il mesure à quel envergure chaque point d'un cluster est similaire aux autres points du même cluster, notamment par rapport aux points des clusters voisins. Le score varie de -1 à 1, où une valeur élevée indique que l'objet est bien adapté à son propre cluster et mal adapté aux clusters voisins.\n",
    "\n",
    "    Un score proche de 1 indique une bonne configuration du clustering.\n",
    "    Un score proche de 0 indique un chevauchement de clusters.\n",
    "    Un score proche de -1 indique une mauvaise affectation au cluster.\n",
    "\n",
    "Sur le papier, c'est bien joli, mais notre graphique ne permet pas une lecture optimale de cette organisation: \n",
    "\n",
    "La courbe monte et descend beaucoup, ce qui peut indiquer une certaine ambiguïté dans la structure des données. Par ailleurs, l'oscillation du score entre 0.41 et 0.34, avec de fortes cassures, indique un flou dans la structure des clusters.\n",
    "La justification peut provenir de la forme irrégulière des clusters, des données d'origine... Quoiqu'il en soit, cela rend le choix du nombre optimal de clusters délicat.\n",
    "\n",
    "Nous allons tenter une autre méthode \"automatique\" de sélection des clusters : l'analyse des inerties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc17576",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reprise de l'ACP\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# mise en place d'un modèle KMeans avec la méthode partielle\n",
    "kmeans_partial = MiniBatchKMeans(n_clusters=k)\n",
    "\n",
    "# calcul des inerties pour différentes valeurs de k\n",
    "inertia_values = []\n",
    "cluster_range = range(1, 11)  # choix d'une plage appropriée de clusters\n",
    "for k in cluster_range:\n",
    "    kmeans_partial.partial_fit(principal_components)\n",
    "    inertia_values.append(kmeans_partial.inertia_)\n",
    "\n",
    "# tracé de la courbe d'inerties\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_range, inertia_values, marker='o')\n",
    "plt.title('Analyse des Inerties')\n",
    "plt.xlabel('Nombre de Clusters')\n",
    "plt.ylabel('Inertie')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6bb705",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Encore une fois, le résultat est ambigu. Trois, quatre ou cinq clusters? Rien ne permet de choisir le bon nombre. Essayons autre chose : le DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb09eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sélection des colonnes à inclure dans l'ACP\n",
    "cols_to_scale = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# standardisation des colonnes sélectionnées\n",
    "scaler = StandardScaler()\n",
    "data_sans_outliers[cols_to_scale] = scaler.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# on réalise l'ACP\n",
    "pca = PCA()\n",
    "pca.fit(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# on cherche les composantes principales\n",
    "principal_components = pca.transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# utilisation de DBSCAN sur les composantes principales\n",
    "dbscan = DBSCAN(eps=1, min_samples=5)\n",
    "clusters_dbscan = dbscan.fit_predict(principal_components)\n",
    "\n",
    "# on crée un nuage de points coloré par cluster\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=clusters_dbscan, cmap='viridis')\n",
    "plt.title('Résultat de DBSCAN sans la colonne Population')\n",
    "plt.xlabel('Composante Principale 1')\n",
    "plt.ylabel('Composante Principale 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f9556",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La méthodes du DBSCAN nous révèle 3 groupes très dispersés, dont le plus important (le violet) s'éparpille dans la moitié droite du cercle des charges factorielles, et se voit concerné par toutes les composantes principales.\n",
    "\n",
    "Il nous faudrait utiliser un autre algorithme, quitte à choisir volontairement le nombre de clusters, afin d'avoir des cercles plus fermés et ainsi limiter le nombre d'individus. Outre une sélection plus précise, nous pourrons peut être voir une corrélation entre chaque cluster et l'ACP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde53750",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dendrogramme, ou Classification Ascendante Hiérarchique <a class=\"anchor\" id=\"section_2_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b81d94",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on exclut la variable 'Population'\n",
    "data_sans_population = data_sans_outliers.drop('Population', axis=1)\n",
    "\n",
    "# on garde uniquement les colonnes numériques\n",
    "data_sans_population_numeric = data_sans_population.select_dtypes(include='number')\n",
    "\n",
    "# calcul de la matrice de liaison\n",
    "linkage_matrix_sans_population = linkage(data_sans_population_numeric, method='ward')\n",
    "\n",
    "# définition d'un \"seuil de coupe\"\n",
    "t = 14\n",
    "\n",
    "# création d'un dendrogramme horizontal\n",
    "fig, ax = plt.subplots(figsize=(12, 20))\n",
    "dendrogram(linkage_matrix_sans_population, labels=data_sans_population['Zone'].tolist(), orientation='left', leaf_rotation=0, leaf_font_size=8, color_threshold=0.8*t)\n",
    "plt.title('Dendrogramme des Pays basé sur l\\'ACP')\n",
    "plt.xlabel('Distance Euclidienne')\n",
    "plt.ylabel('Pays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b6a4e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La sélection de t est arbitraire, mais permet de comparer les différents pays en les séparant en 4 clusters. Par ailleurs, un certain nombre des pays inclus dans le cluster rouge correspond aux pays ayant la plus forte valeur d'importation, comme vu dans un des scatterplots plus haut.\n",
    "\n",
    "Testons avec la méthode du kmeans, afin de pouvoir comparer nos résultats à une autre source et, éventuellement, s'assurer de la stabilité de nos clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e5ef2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Algorithme Kmeans <a class=\"anchor\" id=\"section_2_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55357200",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sélection des colonnes à inclure dans l'ACP\n",
    "cols_to_scale = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# standardisation des les colonnes sélectionnées\n",
    "scaler = StandardScaler()\n",
    "data_sans_outliers[cols_to_scale] = scaler.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# on réalise l'ACP\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(data_sans_outliers[cols_to_scale])\n",
    "\n",
    "# choix défini du nombre de clusters\n",
    "k = 4\n",
    "\n",
    "# on crée l'objet KMeans avec n_init élevé et random_state fixé\n",
    "kmeans = KMeans(n_clusters=k, n_init=50, random_state=42)\n",
    "\n",
    "# ajustement du modèle\n",
    "kmeans.fit(principal_components)\n",
    "\n",
    "# on récupère les étiquettes de cluster\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# coordonnées des centroïdes\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# création d'un nuage de points coloré par cluster\n",
    "plt.figure(figsize=(14, 12))\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=cluster_labels, cmap='viridis')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red')  # centroides en rouge\n",
    "plt.xlabel('Composante Principale 1')\n",
    "plt.ylabel('Composante Principale 2')\n",
    "plt.title('Clustering des Pays basé sur l\\'ACP avec Centroides')\n",
    "plt.grid(True)\n",
    "\n",
    "# noms des pays\n",
    "for i, txt in enumerate(data_sans_outliers['Zone']):\n",
    "    plt.annotate(txt, (principal_components[i, 0], principal_components[i, 1]))\n",
    "\n",
    "# affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f10d5c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nos clusters sont bien représentés, et le centroïde du cluster bleu va clairement dans la direction de l'importation, ce qui semble prometteur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9a66b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Analyse des résultats <a class=\"anchor\" id=\"section_2_2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef722e8a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Analysons les différents résultats obtenus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fdbbc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# on appliquer la découpe de l'arbre en fonction du seuil (t) précédent\n",
    "clusters_dendrogramme = cut_tree(linkage_matrix_sans_population, height=10).flatten()\n",
    "\n",
    "# ajout de la colonne d'étiquettes de cluster au df\n",
    "data_sans_population['Cluster_dendro'] = clusters_dendrogramme\n",
    "\n",
    "# affichage\n",
    "clusters_dendro = data_sans_population.groupby(['Cluster_dendro']).mean().round(2)\n",
    "clusters_dendro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b985f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ajout de la colonne d'étiquettes de cluster au df\n",
    "data_sans_population['Cluster'] = cluster_labels\n",
    "\n",
    "clusters_kmeans = data_sans_population.groupby(['Cluster']).mean().round(2)\n",
    "clusters_kmeans = clusters_kmeans.drop('Cluster_dendro', axis=1)\n",
    "clusters_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cefdaa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# suppression des lignes où les résultats des méthodes de clustering sont les mêmes\n",
    "clusters_différents = data_sans_population[data_sans_population['Cluster'] != data_sans_population['Cluster_dendro']]\n",
    "\n",
    "# affichage du nombre de pays ayant \"changé\" de clusters\n",
    "nombre_de_lignes = clusters_différents.shape[0]\n",
    "print(f\"Nombre de lignes : {nombre_de_lignes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8b5bd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On distingue dans les tableaux d'analyse de moyenne une inversion entre le cluster 1 et le cluster 3, sans compter quelques petites différences entre les chiffres des clusters \"fixes\". Ceci permet de comprendre pourquoi 59 pays semblent avoir changé de cluster.\n",
    "\n",
    "Les écarts de chiffres sont justifiés par la nature même du kmeans et du dendrogramme. Si le premier est basée sur la distance euclidienne entre les différents points, ce n'est pas le cas du second, qui fonctionne sur les relations de similarités entre les composantes, notamment grâce à la \"distance de Ward\" que nous avons utilisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b4d143",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Analysons plus en profondeur les caractéristiques des clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8972c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sélection des colonnes à inclure dans la heatmap\n",
    "cols_to_compare = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# création d'un df avec les colonnes sélectionnées\n",
    "heatmap_data = data_sans_population[cols_to_compare + ['Cluster']]\n",
    "\n",
    "# on cré la heatmap en inversant les axes et en inclinant les noms\n",
    "plt.figure(figsize=(12, 6))\n",
    "heatmap = sns.heatmap(heatmap_data.groupby(['Cluster']).mean(), annot=True, cmap='coolwarm', xticklabels=cols_to_compare, yticklabels='auto')\n",
    "plt.title('Heatmap des Colonnes avec les Clusters')\n",
    "\n",
    "# on tilt les abscisses de 45°\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# on horizontalise les ordonnées (pas de base?)\n",
    "plt.yticks(rotation=0, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d2f0d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La clustermap indique clairement les corrélations avec les composantes de notre dataframe, ce qui nous permet de confirmer que le cluster 2 est le plus intéressant car c'est le regroupement de pays le plus demandeur de ressources. Au contraire, les valeurs des autres clusters sont négatives, ce qui indique que ces clusters sont majoritairement excédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d91a3a",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sélection des colonnes à inclure dans les boxplots\n",
    "cols_to_compare = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# Création d'un DataFrame avec les colonnes sélectionnées et le cluster\n",
    "boxplot_data = data_sans_population[cols_to_compare + ['Cluster']]\n",
    "\n",
    "# Configuration de la taille de la figure\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Boucle sur chaque colonne pour créer des boxplots par cluster\n",
    "for i, col in enumerate(cols_to_compare):\n",
    "    plt.subplot(2, 3, i + 1)  # Réglage de la disposition des sous-plots\n",
    "    sns.boxplot(x='Cluster', y=col, data=boxplot_data, palette='viridis')\n",
    "    plt.title(f'{col}')\n",
    "\n",
    "# Ajustement du placement des sous-plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Affichage de la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d93bd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "L'aperçu par boxplot est un autre moyen visuel de comparer les différents clusters par composante et conforte à nouveau les résultats précédemment obtenus. Maintenant que nous avons déterminé le regroupement de pays le plus intéressant pour notre étude de marché, recherchons le pays le plus \"attractif\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91abf9dd",
   "metadata": {},
   "source": [
    "### Évaluation du cluster conservé <a class=\"anchor\" id=\"section_2_2_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier les données selon le cluster\n",
    "sorted_data = data_sans_population.sort_values(by='Cluster')\n",
    "\n",
    "# Filtrer uniquement les données du cluster 2\n",
    "données_cluster2 = sorted_data[sorted_data['Cluster'] == 2]\n",
    "\n",
    "# Afficher les données du cluster 2\n",
    "données_cluster2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23719d2c",
   "metadata": {},
   "source": [
    "Les valeurs sont encore celles qui ont été standardisées précedemment. Il nous faudra les remplacer par les données d'origine. Pour ce faire, nous allons supprimer les colonnes modifiées de données_cluster2, et le fusionner avec data_fin, que nous avions mis de coté avant de faire la normalisation.\n",
    "\n",
    "Accessoirement, nous pouvons voir que tous les pays, excepté la Namibie et la Géorgie, ont bien été gérés de la même manière par le dendrogramme et kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des colonnes standardisées\n",
    "colonnes_à_supprimer = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production', 'Cluster_dendro']\n",
    "\n",
    "données_cluster2 = données_cluster2.drop(columns=colonnes_à_supprimer)\n",
    "données_cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab042d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion des df cluster2 clean et de data_fin, qu'on avait conservé\n",
    "data_origin_c2 = pd.merge(données_cluster2, data_fin, on=['Zone'], how='inner')\n",
    "\n",
    "# liste des colonnes à modifier suite à la division par habitants\n",
    "colonnes_a_inverser = ['Disponibilité alimentaire en quantité (kg/personne/an)', 'Disponibilité intérieure', 'Exportations - Quantité', 'Importations - Quantité', 'Production']\n",
    "\n",
    "# boucle sur chaque colonne à inverser\n",
    "for colonne in colonnes_a_inverser:\n",
    "    # multiplication par la colonne 'Population'\n",
    "    data_origin_c2[colonne] = data_origin_c2[colonne] * data_origin_c2['Population']\n",
    "    \n",
    "# organisation par importation décroissante\n",
    "data_origin_c2 = data_origin_c2.sort_values(by='Importations - Quantité', ascending=False)\n",
    "\n",
    "data_origin_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde du fichier final\n",
    "data_origin_c2.to_csv(r\"C:\\Users\\Avenmythril\\Desktop\\Formations\\DAn\\Projet 9\\Talbot_Robin_112023_P9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les noms de pays français et ISO A3\n",
    "correspondance_iso = {\n",
    "    'Allemagne': 'DEU',\n",
    "    'Iraq': 'IRQ',\n",
    "    'Arabie saoudite': 'SAU',\n",
    "    'Cuba': 'CUB',\n",
    "    'Tchéquie': 'CZE',\n",
    "    'Autriche': 'AUT',\n",
    "    'Bulgarie': 'BGR',\n",
    "    'Irlande': 'IRL',\n",
    "    'Congo': 'COG',\n",
    "    'Suède': 'SWE',\n",
    "    'Slovaquie': 'SVK',\n",
    "    'Géorgie': 'GEO',\n",
    "    'Macédoine du Nord': 'MKD',\n",
    "    'Albanie': 'ALB',\n",
    "    'Jamaïque': 'JAM',\n",
    "    'Arménie': 'ARM',\n",
    "    'Croatie': 'HRV',\n",
    "    'Namibie': 'NAM',\n",
    "    'Slovénie': 'SVN',\n",
    "    'Timor-Leste': 'TLS',\n",
    "    'Îles Salomon': 'SLB'\n",
    "}\n",
    "\n",
    "# Appliquer la correspondance aux noms de pays dans data_origin_c2\n",
    "data_origin_c2['ISO_A3'] = data_origin_c2['Zone'].map(correspondance_iso)\n",
    "\n",
    "# Utiliser la colonne 'ISO_A3' pour les codes ISO A3 avec une plage de couleurs ajustée\n",
    "fig = px.choropleth(\n",
    "    data_origin_c2,\n",
    "    locations='ISO_A3',\n",
    "    color='Importations - Quantité',\n",
    "    hover_name='Zone',\n",
    "    title='Carte des pays à forte importation',\n",
    "    color_continuous_scale='Reds',\n",
    "    projection='natural earth',\n",
    "    range_color=[data_origin_c2['Importations - Quantité'].min(), data_origin_c2['Importations - Quantité'].max()]  # Ajuster la plage de couleurs\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire de correspondance entre les noms de pays français et anglais\n",
    "correspondance_pays = {\n",
    "    'Allemagne': 'Germany',\n",
    "    'Iraq': 'Iraq',\n",
    "    'Arabie saoudite': 'Saudi Arabia',\n",
    "    'Cuba': 'Cuba',\n",
    "    'Tchéquie': 'Czechia',\n",
    "    'Autriche': 'Austria',\n",
    "    'Bulgarie': 'Bulgaria',\n",
    "    'Irlande': 'Ireland',\n",
    "    'Congo': 'Congo',\n",
    "    'Suède': 'Sweden',\n",
    "    'Slovaquie': 'Slovakia',\n",
    "    'Géorgie': 'Georgia',\n",
    "    'Macédoine du Nord': 'North Macedonia',\n",
    "    'Albanie': 'Albania',\n",
    "    'Jamaïque': 'Jamaica',\n",
    "    'Arménie': 'Armenia',\n",
    "    'Croatie': 'Croatia',\n",
    "    'Namibie': 'Namibia',\n",
    "    'Slovénie': 'Slovenia',\n",
    "    'Timor-Leste': 'Timor-Leste',\n",
    "    'Îles Salomon': 'Solomon Islands'\n",
    "}\n",
    "\n",
    "# Appliquer la correspondance aux noms de pays dans data_origin_c2\n",
    "data_origin_c2['Zone_EnAnglais'] = data_origin_c2['Zone'].map(correspondance_pays)\n",
    "\n",
    "# Charger le fichier de formes des pays\n",
    "path_to_shapefile = r\"C:\\Users\\Avenmythril\\Desktop\\Formations\\DAn\\Projet 9\\110m_cultural\\ne_110m_admin_0_countries.shp\"\n",
    "world = gpd.read_file(path_to_shapefile)\n",
    "\n",
    "# Fusionner les données du tableau avec les données géospatiales\n",
    "merged = world.merge(data_origin_c2, how='left', left_on='NAME', right_on='Zone_EnAnglais', indicator=True)\n",
    "\n",
    "# Créer la colonne 'InDataFrame' pour marquer les pays dans votre DataFrame\n",
    "merged['InDataFrame'] = merged['_merge'] == 'both'\n",
    "\n",
    "# Plot avec GeoPandas et Matplotlib\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "merged.plot(column='InDataFrame', cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)\n",
    "plt.title('Carte des pays à forte importation', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906ce45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
